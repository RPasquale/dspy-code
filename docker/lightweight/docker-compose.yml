services:
    dspy-agent:
      image: dspy-lightweight:latest
      user: "10001:10001"
      build:
        context: ../..
        dockerfile: docker/lightweight/Dockerfile
      environment:
        - LOCAL_MODE=false
        - USE_OLLAMA=true
        - DB_BACKEND=reddb
        - DSPY_AUTO_APPLY_PATCHES=0
        - REDDB_URL=http://reddb:8080
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN=${REDDB_ADMIN_TOKEN}
        - MODEL_NAME=qwen3:1.7b
        - OPENAI_API_KEY=
        - OPENAI_BASE_URL=http://ollama:11434
        - OLLAMA_MODEL=qwen3:1.7b
        - OLLAMA_API_KEY=
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - KAFKA_CLIENT_ID=dspy-agent
        - KAFKA_TOPIC_PREFIX=
        # Cache configuration to fix SQLite syntax errors
        - DSPY_CACHE_DIR=/workspace/.dspy_cache
        - DISKCACHE_DISABLE_SQLITE_OPTIMIZATIONS=1
        - DISKCACHE_DISABLE_SQLITE_PRAGMA=1
        - DISKCACHE_DISABLE_SQLITE_WAL=1
        - DISKCACHE_DISABLE_SQLITE_JOURNAL=1
        # Advanced features
        - DSPY_ENABLE_AUTO_SCALING=true
        - DSPY_PERFORMANCE_MODE=optimized
        - DSPY_INTELLIGENT_CACHING=true
        - DSPY_ADAPTIVE_LEARNING=true
      entrypoint: ["/entrypoints/run_dspy_agent.sh"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ${WORKSPACE_DIR}/logs:/workspace/logs:ro
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      ports:
        - "127.0.0.1:8765:8765"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      tmpfs:
        - /tmp
      cap_drop:
        - ALL
      deploy:
        resources:
          limits:
            memory: 4G
            cpus: '2.0'
          reservations:
            memory: 2G
            cpus: '1.0'
        restart_policy:
          condition: on-failure
          delay: 5s
          max_attempts: 3
          window: 120s
      depends_on:
        kafka:
          condition: service_healthy
        reddb:
          condition: service_healthy

    ollama:
      image: ollama/ollama:latest
      entrypoint: ["/bin/sh", "/entrypoints/run_ollama.sh"]
      ports:
        - "127.0.0.1:11435:11434"
      volumes:
        - ollama:/root/.ollama
        - ./entrypoints:/entrypoints:ro
      environment:
        - OLLAMA_MAX_LOADED_MODELS=1
        - OLLAMA_NUM_PARALLEL=1
        - OLLAMA_MAX_QUEUE=512
      deploy:
        resources:
          limits:
            memory: 6G
            cpus: '4.0'
          reservations:
            memory: 3G
            cpus: '2.0'
        restart_policy:
          condition: on-failure
          delay: 10s
          max_attempts: 3
          window: 300s
      healthcheck:
        test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 20
        start_period: 10s

    zookeeper:
      image: bitnami/zookeeper:3.9
      environment:
        - ALLOW_ANONYMOUS_LOGIN=yes
      ports:
        - "127.0.0.1:2181:2181"
      healthcheck:
        test: ["CMD-SHELL", "echo ruok | nc localhost 2181 || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 20
        start_period: 15s
      deploy:
        resources:
          limits:
            memory: 1G
            cpus: '1.0'
          reservations:
            memory: 512M
            cpus: '0.5'

    kafka:
      image: bitnami/kafka:3.6
      depends_on:
        zookeeper:
          condition: service_healthy
      environment:
        - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
        - ALLOW_PLAINTEXT_LISTENER=yes
        - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
        - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
        - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9092
        - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
        - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
        - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
        - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
        - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
        - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
        - KAFKA_NUM_PARTITIONS=3
        - KAFKA_DEFAULT_REPLICATION_FACTOR=1
      ports:
        - "127.0.0.1:9092:29092"
      healthcheck:
        test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 10s
        retries: 20
        start_period: 30s
      deploy:
        resources:
          limits:
            memory: 2G
            cpus: '2.0'
          reservations:
            memory: 1G
            cpus: '1.0'

    redis:
      image: redis:7-alpine
      command: ["redis-server","--save","","--appendonly","no"]
      ports:
        - "127.0.0.1:6379:6379"
      volumes:
        - redis-data:/data
      healthcheck:
        test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 5s
      restart: unless-stopped
      deploy:
        resources:
          limits:
            memory: 2G
            cpus: '1.0'
          reservations:
            memory: 512M
            cpus: '0.5'

    reddb:
      image: dspy-lightweight:latest
      container_name: reddb
      working_dir: /app
      entrypoint: ["/usr/local/bin/reddb"]
      restart: unless-stopped
      user: root
      ports:
        - "127.0.0.1:8082:8080"
      environment:
        - REDDB_ADMIN_TOKEN=${REDDB_ADMIN_TOKEN}
        - REDDB_DATA_DIR=/data
      volumes:
        - ./data/reddb:/data
      healthcheck:
        test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 10s
      deploy:
        resources:
          limits:
            memory: 1G
            cpus: '1.0'
          reservations:
            memory: 512M
            cpus: '0.5'
      security_opt:
        - no-new-privileges:true
      read_only: true
      tmpfs:
        - /tmp
      cap_drop:
        - ALL

    fastapi-backend:
      image: dspy-lightweight:latest
      user: "10001:10001"
      working_dir: /app
      entrypoint: ["/bin/sh", "-lc", "python -m dspy_agent.server.fastapi_backend"]
      environment:
        - REDDB_URL=http://reddb:8080
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN=${REDDB_ADMIN_TOKEN}
        - DSPY_WORKSPACE=/workspace
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      ports:
        - "127.0.0.1:8767:8767"
      depends_on:
        reddb:
          condition: service_healthy
      healthcheck:
        test: ["CMD-SHELL", "python - <<'PY'\nimport urllib.request as u, sys\ntry:\n u.urlopen('http://localhost:8767/api/db/health')\n sys.exit(0)\nexcept Exception:\n sys.exit(1)\nPY"]
        interval: 20s
        timeout: 5s
        retries: 10
        start_period: 5s
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: false
      tmpfs:
        - /tmp
      cap_drop:
        - ALL

    dspy-embedder:
      image: dspy-lightweight:latest
      entrypoint: ["uvicorn", "dspy_agent.embedding.dspy_embedder_service:app", "--host", "0.0.0.0", "--port", "8080"]
      environment:
        - DSPY_EMBED_MODEL=${DSPY_EMBED_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
        - DSPY_EMBED_NORMALIZE=${DSPY_EMBED_NORMALIZE:-0}
        - DSPY_GEPA_DATASET=${DSPY_GEPA_DATASET:-}
        - DSPY_GEPA_AUTO=${DSPY_GEPA_AUTO:-light}
        - DSPY_GEPA_LOG_DIR=${DSPY_GEPA_LOG_DIR:-}
        - DSPY_LM_MODEL=${DSPY_LM_MODEL:-}
        - DSPY_LM_PROVIDER=${DSPY_LM_PROVIDER:-openai}
        - OPENAI_API_KEY=${OPENAI_API_KEY:-}
        - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      volumes:
        - ${WORKSPACE_DIR}:/workspace
      ports:
        - "127.0.0.1:18082:8080"
      restart: unless-stopped
      healthcheck:
        test: ["CMD-SHELL", "curl -sf http://localhost:8080/health || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    infermesh-node-a:
      image: official-infermesh:latest
      entrypoint: ["/usr/local/bin/meshd", "start", "--config", "/config/node-a.yaml"]
      volumes:
        - ./infermesh-config/node-a.yaml:/config/node-a.yaml:ro
        - infermesh-node-a-data:/app/data
      restart: unless-stopped
      healthcheck:
        test: ["CMD-SHELL", "curl -sf http://localhost:8080/health || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    infermesh-node-b:
      image: official-infermesh:latest
      entrypoint: ["/usr/local/bin/meshd", "start", "--config", "/config/node-b.yaml"]
      volumes:
        - ./infermesh-config/node-b.yaml:/config/node-b.yaml:ro
        - infermesh-node-b-data:/app/data
      restart: unless-stopped
      healthcheck:
        test: ["CMD-SHELL", "curl -sf http://localhost:8080/health || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    infermesh-router:
      image: official-infermesh:latest
      entrypoint: ["/entrypoints/run_official_router.sh"]
      environment:
        - AGENT_SERVICE=infermesh-node-a:50051
        - ROUTER_HTTP_PORT=9000
        - ROUTER_GRPC_PORT=9100
        - ROUTER_MAX_REQUESTS=512
        - ROUTER_REQUEST_TIMEOUT=30
        - DSPY_EMBEDDER_URL=http://dspy-embedder:8080/embed
      volumes:
        - ./entrypoints:/entrypoints:ro
      depends_on:
        infermesh-node-a:
          condition: service_healthy
        dspy-embedder:
          condition: service_healthy
      ports:
        - "127.0.0.1:${INFERMESH_HOST_PORT:-19000}:9000"
      healthcheck:
        test: ["CMD-SHELL", "curl -sf http://localhost:9000/health || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s
      restart: unless-stopped

    # Dedicated dashboard service (serves enhanced_dashboard_server on port 8081)
    dashboard:
      image: dspy-lightweight:latest
      user: "10001:10001"
      working_dir: /app
      entrypoint: ["bash", "-lc", "cd /workspace && python3 enhanced_dashboard_server.py 8081"]
      environment:
        - WORKSPACE_DIR=/workspace
        - DSPY_WORKSPACE=/workspace
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      ports:
        - "127.0.0.1:18081:8081"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      # Allow server to write .dspy_reports under /app
      read_only: false
      cap_drop:
        - ALL
      depends_on:
        kafka:
          condition: service_healthy

    embed-worker:
      build:
        context: ../..
        dockerfile: docker/lightweight/embed_worker.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
        infermesh-router:
          condition: service_started
      environment:
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - EMBED_INPUT_TOPIC=embedding_input
        - EMBED_OUTPUT_TOPIC=embeddings
        - EMBED_GROUP=embed-worker
        - EMBED_BACKEND=infermesh
        - INFERMESH_URL=http://infermesh-router:9000
        - EMBED_MODEL=${INFERMESH_MODEL:-BAAI/bge-small-en-v1.5}
        - EMBED_BATCH_SIZE=${EMBED_BATCH_SIZE:-64}
        - EMBED_MAX_WAIT_SEC=${EMBED_MAX_WAIT_SEC:-0.5}
        - EMBED_WRITE_PARQUET=1
        - EMBED_NORMALIZE=${EMBED_NORMALIZE:-0}
        - EMBED_PARQUET_DIR=/workspace/vectorized/embeddings_imesh
        - INFERMESH_ROUTING_STRATEGY=${INFERMESH_ROUTING_STRATEGY:-hybrid}
        - INFERMESH_CACHE_TTL=${INFERMESH_CACHE_TTL:-300}
        - REDDB_URL
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN
        - REDDB_STREAM=embeddings
        - REDDB_MODE=stream
        - EMBED_METRICS_PORT=9100
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./dspy_agent/streaming:/app/dspy_agent/streaming:ro
        - ./entrypoints:/entrypoints:ro
        - hf-cache:/root/.cache/huggingface
      entrypoint: ["/bin/sh", "-lc", "sh /entrypoints/run_embed_worker.sh"]
      ports:
        - "127.0.0.1:9101:9100"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "python -c \"import urllib.request as u; u.urlopen('http://localhost:9100/health')\" >/dev/null 2>&1 || exit 1"]
        interval: 20s
        timeout: 5s
        retries: 10
        start_period: 15s

    spark:
      image: bitnami/spark:3.5
      depends_on:
        kafka:
          condition: service_healthy
      user: "0:0"
      environment:
        - HOME=/tmp
        - USER=spark
        - SPARK_USER=spark
        - HADOOP_USER_NAME=spark
        - SPARK_LOCAL_DIRS=/tmp
        - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./dspy_agent/streaming:/app/dspy_agent/streaming:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/entrypoints/run_spark.sh"]
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'spark_logs.py' >/dev/null 2>&1 || exit 1"]
        interval: 30s
        timeout: 5s
        retries: 10
        start_period: 20s

    dspy-worker:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      environment:
        # Cache configuration to fix SQLite syntax errors
        - DSPY_CACHE_DIR=/workspace/.dspy_cache
        - DISKCACHE_DISABLE_SQLITE_OPTIMIZATIONS=1
        - DISKCACHE_DISABLE_SQLITE_PRAGMA=1
        - DISKCACHE_DISABLE_SQLITE_WAL=1
        - DISKCACHE_DISABLE_SQLITE_JOURNAL=1
      entrypoint: ["/entrypoints/run_worker.sh", "app"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'dspy-agent worker --topic app' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-worker-backend:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/entrypoints/run_worker.sh", "backend"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'dspy-agent worker --topic backend' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-worker-frontend:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      environment:
        # Cache configuration to fix SQLite syntax errors
        - DSPY_CACHE_DIR=/workspace/.dspy_cache
        - DISKCACHE_DISABLE_SQLITE_OPTIMIZATIONS=1
        - DISKCACHE_DISABLE_SQLITE_PRAGMA=1
        - DISKCACHE_DISABLE_SQLITE_WAL=1
        - DISKCACHE_DISABLE_SQLITE_JOURNAL=1
      entrypoint: ["/entrypoints/run_worker.sh", "frontend"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'dspy-agent worker --topic frontend' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    # One-off test runner for the lightweight image. Mounts your workspace and
    # installs pytest into HOME (/workspace) to keep the image minimal.
    agent-tests:
      image: dspy-lightweight:latest
      environment:
        - HOME=/workspace
      working_dir: /workspace
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      entrypoint: ["/bin/sh", "-lc"]
      command: |
        "python -m pip install --user -q pytest && \
         python -m pytest -q"
      restart: "no"
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL

    dspy-code-watch:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/bin/bash", "-lc"]
      command: >-
        python - <<'PY'
        from dspy_agent.code_tools.code_watch import CodeWatcher
        from pathlib import Path
        CodeWatcher(Path('/workspace')).run()
        PY
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'code_watch' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-code-indexer:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/bin/bash", "-lc"]
      command: >-
        python - <<'PY'
        from dspy_agent.code_tools.code_indexer_worker import CodeIndexerWorker
        CodeIndexerWorker('kafka:9092').run()
        PY
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'code_indexer_worker' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-router:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/entrypoints/run_router.sh"]
      volumes:
        - ./entrypoints:/entrypoints:ro
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'router_worker' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    rl-trainer:
      image: dspy-lightweight:latest
      user: "10001:10001"
      entrypoint: ["/bin/bash","-lc"]
      command: >-
        python -m dspy_agent.training.entrypoint \
          --workspace /workspace \
          --signature CodeContextSig \
          --verifiers dspy_agent.verifiers.custom \
          --steps 200 \
          --env development
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      restart: on-failure
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
    emb-indexer:
      build:
        context: ../..
        dockerfile: docker/lightweight/embed_worker.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
      environment:
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - EMB_INDEX_TOPIC=embeddings
        - EMB_INDEX_GROUP=emb-indexer
        - REDDB_URL
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN
        - REDDB_INDEX_STREAM=emb_index
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./dspy_agent/streaming:/app/dspy_agent/streaming:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/bin/sh", "-lc", "sh /entrypoints/run_emb_indexer.sh"]
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
    spark-vectorizer:
      build:
        context: .
        dockerfile: spark_vectorizer.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
      user: "0:0"
      environment:
        - HOME=/tmp
        - USER=spark
        - SPARK_USER=spark
        - HADOOP_USER_NAME=spark
        - SPARK_LOCAL_DIRS=/tmp
        - SPARK_CONF_DIR=/opt/bitnami/spark/conf
        - KAFKA_BOOTSTRAP=kafka:9092
        - SPARK_KAFKA_TOPICS=agent.results
        - VEC_OUTPUT_DIR=/workspace/vectorized/embeddings
        - VEC_CHECKPOINT=/workspace/.dspy_checkpoints/vectorizer
        - SINK_INPUT_TOPIC=embedding_input
        # Additional startup delay to ensure Kafka is fully ready
        - SPARK_STARTUP_DELAY=10
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./dspy_agent/streaming:/app/dspy_agent/streaming:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/bin/bash", "-lc", "source /entrypoints/run_spark_vectorizer.sh"]
      ports:
        - "127.0.0.1:4041:4040"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: false
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "exit 0"]
        interval: 30s
        timeout: 5s
        retries: 1
        start_period: 1s

    smoke:
      build:
        context: ../..
        dockerfile: docker/lightweight/embed_worker.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
        # spark-vectorizer is optional for local dev; don't block on health
        spark-vectorizer:
          condition: service_started
        embed-worker:
          condition: service_healthy
      environment:
        - KAFKA_BOOTSTRAP=kafka:9092
        - RESULTS_TOPIC=agent.results
        - EMBED_PARQUET_DIR=/workspace/vectorized/embeddings_imesh
        - N_MESSAGES=5
        - SLEEP_SEC=6
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/bin/sh", "-lc", "sh /entrypoints/run_smoke.sh"]
      restart: "no"
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL

    test-suite:
      build:
        context: .
        dockerfile: test_suite.Dockerfile
      environment:
        - WORKSPACE_DIR=${WORKSPACE_DIR}
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./logs:/workspace/logs
      depends_on:
        - dspy-agent
        - dashboard
      profiles:
        - testing

    # Intelligent auto-scaling service
    auto-scaler:
      image: dspy-lightweight:latest
      user: "10001:10001"
      working_dir: /app
      entrypoint: ["/bin/bash", "-lc"]
      command: >-
        python - <<'PY'
        from dspy_agent.monitor.auto_scaler import AutoScaler
        import os
        scaler = AutoScaler(
            workspace=os.getenv('WORKSPACE_DIR', '/workspace'),
            kafka_bootstrap=os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'kafka:9092'),
            reddb_url=os.getenv('REDDB_URL', 'http://reddb:8080')
        )
        scaler.start_monitoring()
        PY
      environment:
        - WORKSPACE_DIR=/workspace
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - REDDB_URL=http://reddb:8080
        - REDDB_TOKEN=${REDDB_ADMIN_TOKEN}
        - AUTO_SCALER_INTERVAL=30
        - AUTO_SCALER_CPU_THRESHOLD=80
        - AUTO_SCALER_MEMORY_THRESHOLD=85
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
      depends_on:
        kafka:
          condition: service_healthy
        reddb:
          condition: service_healthy
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      tmpfs:
        - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'auto_scaler' >/dev/null 2>&1 || exit 1"]
        interval: 30s
        timeout: 5s
        retries: 5
        start_period: 10s

    # Go Orchestrator Service
    go-orchestrator:
      image: dspy-lightweight:latest
      build:
        context: ../..
        dockerfile: docker/lightweight/Dockerfile
      environment:
        - ORCHESTRATOR_PORT=9097
        - INFERMESH_BASE_URL=http://infermesh-router:9000
        - INFERMESH_API_KEY=${INFERMESH_API_KEY:-}
        - INFERMESH_MODEL=${INFERMESH_MODEL:-BAAI/bge-small-en-v1.5}
        - REDIS_URL=redis://redis:6379
        - METRICS_ENABLED=true
        - ORCHESTRATOR_DEMO=0
        - ENV_QUEUE_DIR=/app/logs/env_queue
      entrypoint: ["/usr/local/bin/orchestrator"]
      ports:
        - "127.0.0.1:9097:9097"
      volumes:
        - ./logs:/app/logs
      depends_on:
        - redis
        - infermesh-router
      restart: unless-stopped
      healthcheck:
        test: ["CMD-SHELL", "curl -f http://localhost:9097/metrics || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 10s
      deploy:
        resources:
          limits:
            memory: 2G
            cpus: '2.0'
          reservations:
            memory: 512M
            cpus: '0.5'

    # Rust Environment Runner Service
    rust-env-runner:
      image: dspy-lightweight:latest
      build:
        context: ../..
        dockerfile: docker/lightweight/Dockerfile
      environment:
        - INFERMESH_BASE_URL=http://infermesh-router:9000
        - INFERMESH_API_KEY=${INFERMESH_API_KEY:-}
        - INFERMESH_MODEL=${INFERMESH_MODEL:-BAAI/bge-small-en-v1.5}
        - MAX_CONCURRENT_REQUESTS=100
        - BATCH_SIZE=512
        - CONNECTION_POOL_SIZE=50
        - REDIS_URL=redis://redis:6379
        - ENV_QUEUE_DIR=/app/logs/env_queue
        - METRICS_PORT=8080
      entrypoint: ["/usr/local/bin/env_runner"]
      ports:
        - "127.0.0.1:8081:8080"
      volumes:
        - ./logs:/app/logs
      depends_on:
        - redis
        - infermesh-router
        - go-orchestrator
      restart: unless-stopped
      healthcheck:
        test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 15s
      deploy:
        resources:
          limits:
            memory: 4G
            cpus: '4.0'
          reservations:
            memory: 1G
            cpus: '1.0'


volumes:
  ollama: {}
  dspy-cache: {}
  hf-cache: {}
  reddb_data: {}
  redis-data: {}
  infermesh-node-a-data: {}
  infermesh-node-b-data: {}
