services:
    dspy-agent:
      image: dspy-lightweight:latest
      user: "10001:10001"
      build:
        context: .
        dockerfile: Dockerfile
      environment:
        - LOCAL_MODE=false
        - USE_OLLAMA=true
        - DB_BACKEND=reddb
        - DSPY_AUTO_APPLY_PATCHES=0
        - REDDB_URL=http://reddb:8080
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN=${REDDB_ADMIN_TOKEN}
        - MODEL_NAME=qwen3:1.7b
        - OPENAI_API_KEY=
        - OPENAI_BASE_URL=http://ollama:11434
        - OLLAMA_MODEL=qwen3:1.7b
        - OLLAMA_API_KEY=
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - KAFKA_CLIENT_ID=dspy-agent
        - KAFKA_TOPIC_PREFIX
        # Advanced features
        - DSPY_ENABLE_AUTO_SCALING=true
        - DSPY_PERFORMANCE_MODE=optimized
        - DSPY_INTELLIGENT_CACHING=true
        - DSPY_ADAPTIVE_LEARNING=true
      entrypoint: ["/entrypoints/run_dspy_agent.sh"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ${WORKSPACE_DIR}/logs:/workspace/logs:ro
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      ports:
        - "127.0.0.1:8765:8765"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      tmpfs:
        - /tmp
      cap_drop:
        - ALL
      deploy:
        resources:
          limits:
            memory: 4G
            cpus: '2.0'
          reservations:
            memory: 2G
            cpus: '1.0'
        restart_policy:
          condition: on-failure
          delay: 5s
          max_attempts: 3
          window: 120s
      depends_on:
        kafka:
          condition: service_healthy
        reddb:
          condition: service_healthy

    ollama:
      image: ollama/ollama:latest
      entrypoint: ["/bin/sh", "/entrypoints/run_ollama.sh"]
      ports:
        - "127.0.0.1:11435:11434"
      volumes:
        - ollama:/root/.ollama
        - ./entrypoints:/entrypoints:ro
      environment:
        - OLLAMA_MAX_LOADED_MODELS=1
        - OLLAMA_NUM_PARALLEL=1
        - OLLAMA_MAX_QUEUE=512
      deploy:
        resources:
          limits:
            memory: 6G
            cpus: '4.0'
          reservations:
            memory: 3G
            cpus: '2.0'
        restart_policy:
          condition: on-failure
          delay: 10s
          max_attempts: 3
          window: 300s
      healthcheck:
        test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 20
        start_period: 10s

    zookeeper:
      image: bitnami/zookeeper:3.9
      environment:
        - ALLOW_ANONYMOUS_LOGIN=yes
      ports:
        - "127.0.0.1:2181:2181"

    kafka:
      image: bitnami/kafka:3.6
      depends_on:
        - zookeeper
      environment:
        - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
        - ALLOW_PLAINTEXT_LISTENER=yes
        - KAFKA_LISTENERS=PLAINTEXT://:9092
        - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
        - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      ports:
        - "127.0.0.1:9092:9092"
      healthcheck:
        test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
        interval: 10s
        timeout: 3s
        retries: 20
        start_period: 10s

    reddb:
      image: dspy-lightweight:latest
      container_name: reddb-mock
      working_dir: /app
      entrypoint: ["bash", "-lc", "python -m dspy_agent.server.reddb_mock"]
      restart: unless-stopped
      ports:
        - "127.0.0.1:8082:8080"
      environment:
        - REDB_ADMIN_TOKEN=${REDDB_ADMIN_TOKEN}
      healthcheck:
        test: ["CMD-SHELL", "python -c \"import urllib.request as u; u.urlopen('http://localhost:8080/health')\" >/dev/null 2>&1 || exit 1"]
        interval: 30s
        timeout: 10s
        retries: 5
        start_period: 5s
      security_opt:
        - no-new-privileges:true
      read_only: true
      tmpfs:
        - /tmp
      cap_drop:
        - ALL

    fastapi-backend:
      image: dspy-lightweight:latest
      user: "10001:10001"
      working_dir: /app
      entrypoint: ["/bin/sh", "-lc", "python -m dspy_agent.server.fastapi_backend"]
      environment:
        - REDDB_URL=http://reddb:8080
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN=${REDDB_ADMIN_TOKEN}
        - DSPY_WORKSPACE=/workspace
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      ports:
        - "127.0.0.1:8767:8767"
      depends_on:
        reddb:
          condition: service_healthy
      healthcheck:
        test: ["CMD-SHELL", "python - <<'PY'\nimport urllib.request as u, sys\ntry:\n u.urlopen('http://localhost:8767/api/db/health')\n sys.exit(0)\nexcept Exception:\n sys.exit(1)\nPY"]
        interval: 20s
        timeout: 5s
        retries: 10
        start_period: 5s
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: false
      tmpfs:
        - /tmp
      cap_drop:
        - ALL

    infermesh:
      image: ghcr.io/rpasquale/infermesh:cpu-local
      build:
        context: .
        dockerfile: infermesh_cpu.Dockerfile
      environment:
        - MODEL_ID=${INFERMESH_MODEL:-BAAI/bge-small-en-v1.5}
      ports:
        - "127.0.0.1:${INFERMESH_HOST_PORT:-19000}:9000"
      restart: unless-stopped
      volumes:
        - hf-cache:/root/.cache/huggingface
      healthcheck:
        test: ["CMD-SHELL", "python -c \"import urllib.request as u; u.urlopen('http://localhost:9000/health')\" >/dev/null 2>&1 || exit 1"]
        interval: 10s
        timeout: 3s
        retries: 10
        start_period: 5s

    # Dedicated dashboard service (serves enhanced_dashboard_server on port 8081)
    dashboard:
      image: dspy-lightweight:latest
      user: "10001:10001"
      working_dir: /app
      entrypoint: ["bash", "-lc", "cd /workspace && python3 enhanced_dashboard_server.py 8081"]
      environment:
        - WORKSPACE_DIR=/workspace
        - DSPY_WORKSPACE=/workspace
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      ports:
        - "127.0.0.1:18081:8081"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      # Allow server to write .dspy_reports under /app
      read_only: false
      cap_drop:
        - ALL
      depends_on:
        kafka:
          condition: service_healthy

    embed-worker:
      build:
        context: ../..
        dockerfile: docker/lightweight/embed_worker.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
        infermesh:
          condition: service_started
      environment:
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - EMBED_INPUT_TOPIC=embedding_input
        - EMBED_OUTPUT_TOPIC=embeddings
        - EMBED_GROUP=embed-worker
        - EMBED_BACKEND=infermesh
        - INFERMESH_URL=http://infermesh:9000
        - EMBED_MODEL=${INFERMESH_MODEL:-BAAI/bge-small-en-v1.5}
        - EMBED_BATCH_SIZE=${EMBED_BATCH_SIZE:-64}
        - EMBED_MAX_WAIT_SEC=${EMBED_MAX_WAIT_SEC:-0.5}
        - EMBED_WRITE_PARQUET=1
        - EMBED_NORMALIZE=${EMBED_NORMALIZE:-0}
        - EMBED_PARQUET_DIR=/workspace/vectorized/embeddings_imesh
        - REDDB_URL
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN
        - REDDB_STREAM=embeddings
        - REDDB_MODE=stream
        - EMBED_METRICS_PORT=9100
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./scripts:/app/scripts:ro
        - ./entrypoints:/entrypoints:ro
        - hf-cache:/root/.cache/huggingface
      entrypoint: ["/bin/sh", "-lc", "sh /entrypoints/run_embed_worker.sh"]
      ports:
        - "127.0.0.1:9101:9100"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "python -c \"import urllib.request as u; u.urlopen('http://localhost:9100/health')\" >/dev/null 2>&1 || exit 1"]
        interval: 20s
        timeout: 5s
        retries: 10
        start_period: 15s

    spark:
      image: bitnami/spark:3.5
      depends_on:
        kafka:
          condition: service_healthy
      user: "0:0"
      environment:
        - HOME=/tmp
        - USER=spark
        - SPARK_USER=spark
        - HADOOP_USER_NAME=spark
        - SPARK_LOCAL_DIRS=/tmp
        - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./scripts:/app/scripts:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/entrypoints/run_spark.sh"]
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'spark_logs.py' >/dev/null 2>&1 || exit 1"]
        interval: 30s
        timeout: 5s
        retries: 10
        start_period: 20s

    dspy-worker:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/entrypoints/run_worker.sh", "app"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'dspy-agent worker --topic app' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-worker-backend:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/entrypoints/run_worker.sh", "backend"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'dspy-agent worker --topic backend' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-worker-frontend:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/entrypoints/run_worker.sh", "frontend"]
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
        - dspy-cache:/home/agent/.dspy_cache:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'dspy-agent worker --topic frontend' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    # One-off test runner for the lightweight image. Mounts your workspace and
    # installs pytest into HOME (/workspace) to keep the image minimal.
    agent-tests:
      image: dspy-lightweight:latest
      environment:
        - HOME=/workspace
      working_dir: /workspace
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      entrypoint: ["/bin/sh", "-lc"]
      command: |
        "python -m pip install --user -q pytest && \
         python -m pytest -q"
      restart: "no"
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL

    dspy-code-watch:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/bin/bash", "-lc"]
      command: >-
        python - <<'PY'
        from dspy_agent.code_tools.code_watch import CodeWatcher
        from pathlib import Path
        CodeWatcher(Path('/workspace')).run()
        PY
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'code_watch' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-code-indexer:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/bin/bash", "-lc"]
      command: >-
        python - <<'PY'
        from dspy_agent.code_tools.code_indexer_worker import CodeIndexerWorker
        CodeIndexerWorker('kafka:9092').run()
        PY
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'code_indexer_worker' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    dspy-router:
      image: dspy-lightweight:latest
      user: "10001:10001"
      depends_on:
        kafka:
          condition: service_healthy
      entrypoint: ["/entrypoints/run_router.sh"]
      volumes:
        - ./entrypoints:/entrypoints:ro
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'router_worker' >/dev/null 2>&1 || exit 1"]
        interval: 15s
        timeout: 5s
        retries: 10
        start_period: 10s

    rl-trainer:
      image: dspy-lightweight:latest
      user: "10001:10001"
      entrypoint: ["/bin/bash","-lc"]
      command: >-
        python -m dspy_agent.training.entrypoint \
          --workspace /workspace \
          --signature CodeContextSig \
          --verifiers dspy_agent.verifiers.custom \
          --steps 200 \
          --env development
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
      restart: on-failure
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
    emb-indexer:
      build:
        context: ../..
        dockerfile: docker/lightweight/embed_worker.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
      environment:
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - EMB_INDEX_TOPIC=embeddings
        - EMB_INDEX_GROUP=emb-indexer
        - REDDB_URL
        - REDDB_NAMESPACE=dspy
        - REDDB_TOKEN
        - REDDB_INDEX_STREAM=emb_index
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./scripts:/app/scripts:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/bin/sh", "-lc", "sh /entrypoints/run_emb_indexer.sh"]
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
    spark-vectorizer:
      build:
        context: .
        dockerfile: spark_vectorizer.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
      user: "0:0"
      environment:
        - HOME=/tmp
        - USER=spark
        - SPARK_USER=spark
        - HADOOP_USER_NAME=spark
        - SPARK_LOCAL_DIRS=/tmp
        - SPARK_CONF_DIR=/opt/bitnami/spark/conf
        - KAFKA_BOOTSTRAP=kafka:9092
        - SPARK_KAFKA_TOPICS=agent.results
        - VEC_OUTPUT_DIR=/workspace/vectorized/embeddings
        - VEC_CHECKPOINT=/workspace/.dspy_checkpoints/vectorizer
        - SINK_INPUT_TOPIC=embedding_input
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./scripts:/app/scripts:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/bin/bash", "-lc", "source /entrypoints/run_spark_vectorizer.sh"]
      ports:
        - "127.0.0.1:4041:4040"
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: false
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "exit 0"]
        interval: 30s
        timeout: 5s
        retries: 1
        start_period: 1s

    smoke:
      build:
        context: ../..
        dockerfile: docker/lightweight/embed_worker.Dockerfile
      depends_on:
        kafka:
          condition: service_healthy
        # spark-vectorizer is optional for local dev; don't block on health
        spark-vectorizer:
          condition: service_started
        embed-worker:
          condition: service_healthy
      environment:
        - KAFKA_BOOTSTRAP=kafka:9092
        - RESULTS_TOPIC=agent.results
        - EMBED_PARQUET_DIR=/workspace/vectorized/embeddings_imesh
        - N_MESSAGES=5
        - SLEEP_SEC=6
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./scripts:/app/scripts:ro
        - ./entrypoints:/entrypoints:ro
      entrypoint: ["/bin/sh", "-lc", "sh /entrypoints/run_smoke.sh"]
      restart: "no"
      security_opt:
        - no-new-privileges:true
      read_only: true
      # tmpfs disabled for compatibility; uncomment if needed
      # tmpfs:
      #   - /tmp
      cap_drop:
        - ALL

    test-suite:
      build:
        context: .
        dockerfile: test_suite.Dockerfile
      environment:
        - WORKSPACE_DIR=${WORKSPACE_DIR}
      volumes:
        - ${WORKSPACE_DIR}:/workspace
        - ./logs:/workspace/logs
      depends_on:
        - dspy-agent
        - dashboard
      profiles:
        - testing

    # Intelligent auto-scaling service
    auto-scaler:
      image: dspy-lightweight:latest
      user: "10001:10001"
      working_dir: /app
      entrypoint: ["/bin/bash", "-lc"]
      command: >-
        python - <<'PY'
        from dspy_agent.monitor.auto_scaler import AutoScaler
        import os
        scaler = AutoScaler(
            workspace=os.getenv('WORKSPACE_DIR', '/workspace'),
            kafka_bootstrap=os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'kafka:9092'),
            reddb_url=os.getenv('REDDB_URL', 'http://reddb:8080')
        )
        scaler.start_monitoring()
        PY
      environment:
        - WORKSPACE_DIR=/workspace
        - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
        - REDDB_URL=http://reddb:8080
        - REDDB_TOKEN=${REDDB_ADMIN_TOKEN}
        - AUTO_SCALER_INTERVAL=30
        - AUTO_SCALER_CPU_THRESHOLD=80
        - AUTO_SCALER_MEMORY_THRESHOLD=85
      volumes:
        - ${WORKSPACE_DIR}:/workspace:rw
        - ./entrypoints:/entrypoints:ro
      depends_on:
        kafka:
          condition: service_healthy
        reddb:
          condition: service_healthy
      restart: unless-stopped
      security_opt:
        - no-new-privileges:true
      read_only: true
      tmpfs:
        - /tmp
      cap_drop:
        - ALL
      healthcheck:
        test: ["CMD-SHELL", "pgrep -f 'auto_scaler' >/dev/null 2>&1 || exit 1"]
        interval: 30s
        timeout: 5s
        retries: 5
        start_period: 10s
volumes:
  ollama: {}
  dspy-cache: {}
  hf-cache: {}
  reddb_data: {}
